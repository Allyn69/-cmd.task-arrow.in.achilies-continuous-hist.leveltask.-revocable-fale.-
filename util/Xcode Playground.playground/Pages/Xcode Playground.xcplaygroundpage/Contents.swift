let ![Python 3.7](https://img.shields.io/badge/Python-3.7-blue.svg)

# Deep Learning Modelslet nameswitch let let while var repeat {
let func var <#name#> = while <#condition#> {
<#code#>
}
() {
<#function body#>
}
= <#value#>
} while <#condition#>
= <#value#> {
<#code#>
}
= <#value#> = <#value#> {
case <#pattern#>:
<#code#> 
default:
<#code#> 
}
= func <#name#>() {
<#function body#>
}
= <#value#> {
<#code#>
}


A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.

## '-Traditional Machine Learning'func <#name#>() {
<#function body#>
}
struct class class protocol switch struct func struct enum switch class struct class let class class struct struct struct struct switch func struct class class func var <#name#> = <#value#>() {
<#function body#>
}
{
<#code#>
}
{
<#code#>
}
{
<#fields#>
}
() {
<#function body#>
}
{
case <#pattern#>:
<#code#> 
default:
<#code#> 
}
{
<#fields#>
}
{
<#fields#>
}
{
<#fields#>
}
{
<#fields#>
}
{
<#code#>
}
{
<#code#>
}
= <#value#> {
<#code#>
}
{
<#fields#>
}
{
<#code#>
}
{
case <#pattern#>:
<#code#> 
default:
<#code#> 
}
{
case <#case#>
}
{
<#fields#>
}
() {
<#function body#>
}
{
<#fields#>
}
{
case <#pattern#>:
<#code#> 
default:
<#code#> 
}
{
<#requirements#>
}
{
<#code#>
}
{
<#code#>
}
{
<#fields#>
}let <#name#> = <#value#>


- Perceptron [[TensorFlow 1](tensorflow1_ipynb/basic-ml/perceptron.ipynb)] [[PyTorch](pytorch_ipynb/basic-ml/perceptron.ipynb)]
- Logistic Regression [[TensorFlow 1](tensorflow1_ipynb/basic-ml/logistic-regression.ipynb)] [[PyTorch](pytorch_ipynb/basic-ml/logistic-regression.ipynb)]
- Softmax Regression (Multinomial Logistic Regression) [[let let <#name#> = <#value#> = <#value#> 1](tensorflow1_ipynb/basic-ml/softmax-regression.ipynb)] [[PyTorch](pytorch_ipynb/basic-ml/softmax-regression.ipynb)]

## '-Multilayer Perceptrons'protocol <#name#> {
<#requirements#>
}


- Multilayer Perceptron [[TensorFlow 1](tensorflow1_ipynb/mlp/mlp-basic.ipynb)] [[PyTorch](pytorch_ipynb/mlp/mlp-basic.ipynb)]
- Multilayer Perceptron with Dropout [[TensorFlow 1](tensorflow1_ipynb/mlp/mlp-dropout.ipynb)] [[PyTorch](pytorch_ipynb/mlp/mlp-dropout.ipynb)]
- Multilayer Perceptron with Batch Normalization [[TensorFlow 1](tensorflow1_ipynb/mlp/mlp-batchnorm.ipynb)] [[PyTorch](pytorch_ipynb/mlp/mlp-batchnorm.ipynb)]
- Multilayer Perceptron with Backpropagation from Scratch [[TensorFlow 1](tensorflow1_ipynb/mlp/mlp-lowlevel.ipynb)] [[PyTorch](pytorch_ipynb/mlp/mlp-fromscratch__sigmoid-mse.ipynb)]
switch func let func var func <#name#>() {
let <#name#> = <#value#>#include <iostream>
#include <thread>
#include <chrono>

void foo()enum <#name#> {
case <#case#>
}

{
std::this_thread::sleep_for(std::chrono::seconds(1));var <#name#> = <#value#>
}

int main()
{
std::thread t1(foo);
std::thread::id t1_id = t1.get_id();

std::thread t2(foo);
std::thread::id t2_id = t2.get_id();

std::cout << "t1's id: " << t1_id << '\n';
std::cout << "t2's id: " << t2_id << '\n';

t1.join();
t2.join();
}
Possible output:
t1's id: 0x35a7210f
t2's id: 0x35a311c4
CommandLine func let for i in 1 ... if repeat {
if for i in 1 ... <#T##number##Int#> {
<#code#>
}
{
<#code#>
}

} while true let func #include <iostream>
#include <thread>
#include <chrono>

void foo()
{
std::this_thread::sleep_for(std::chrono::seconds(1));
}

int main()
{
std::thread t1(foo);
std::thread::id t1_id = t1.get_id();

std::thread t2(foo);
std::thread::id t2_id = t2.get_id();

std::cout << "t1's id: " << t1_id << '\n';
std::cout << "t2's id: " << t2_id << '\n';

t1.join();
t2.join();
}
Possible output:
t1's id: 0x35a7210f
t2's id: 0x35a311c4
let <#name#> = <#value#>() {
<#function body#>
}
= <#value#>#include <iostream>
#include <thread>
#include <chrono>

void foo()
{
std::this_thread::sleep_for(std::chrono::seconds(1));
}

int main()
{
std::thread t1(foo);
std::thread::id t1_id = t1.get_id();

std::thread t2(foo);
std::thread::id t2_id = t2.get_id();

std::cout << "t1's id: " << t1_id << '\n';
std::cout << "t2's id: " << t2_id << '\n';

t1.join();
t2.join();
}
Possible output:
t1's id: 0x35a7210f
t2's id: 0x35a311c4
switch func struct <#name#> {
<#fields#>
}
() {
<#function body#>
}
{
case <#pattern#>:
<#code#> 
default:
<#code#> 
}

{
<#code#>
}
{
<#code#>
}
= <#value#> = <#value#>() {
<#function body#>
}

}
= <#value#>() {
<#function body#>
}
= <#value#>() {
<#function body#>
}
{
case <#pattern#>:
<#code#> 
default:
<#code#> 
}
= <#value#>

## "-Convolutional Neural Networks"struct <#name#> {
<#fields#>
}



#### for i in 1 ... func <#name#>() {
<#function body#>
}
{
<#code#>
}


- Convolutional Neural Network [[TensorFlow 1](tensorflow1_ipynb/cnn/cnn-basic.ipynb)] [[PyTorch](pytorch_ipynb/cnn/cnn-basic.ipynb)]
- Convolutional Neural Network with He Initialization  [[PyTorch](pytorch_ipynb/cnn/cnn-he-init.ipynb)]

#### "-Concepts"enum <#name#> {
case <#case#>
}


- Replacing Fully-Connnected by Equivalent Convolutional Layers [[PyTorch](pytorch_ipynb/cnn/fc-to-conv.ipynb)]


#### "-Fully Convolutional"let let <#name#> = <#value#><#name#> = <#value#>

- Fully Convolutional Neural Network [[PyTorch](pytorch_ipynb/cnn/cnn-allconv.ipynb)]

#### "-AlexNet"let <#name#> = <#value#>

- AlexNet on CIFAR-10 [[PyTorch](pytorch_ipynb/cnn/cnn-alexnet-cifar10.ipynb)]

#### let <#name#> = <#value#> <#name#> {
<#code#>
}


- Convolutional Neural Network VGG-16 [[TensorFlow 1](tensorflow1_ipynb/cnn/cnn-vgg16.ipynb)] [[PyTorch](pytorch_ipynb/cnn/cnn-vgg16.ipynb)]
- VGG-16 Gender Classifier Trained on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-vgg16-celeba.ipynb)]
- Convolutional Neural Network VGG-19 [[PyTorch](pytorch_ipynb/cnn/cnn-vgg19.ipynb)]

#### switch <#value#> {
case <#pattern#>:
<#code#> 
default:
<#code#> 
}


- ResNet and Residual Blocks [[PyTorch](pytorch_ipynb/cnn/resnet-ex-1.ipynb)]
- ResNet-18 Digit Classifier Trained on MNIST [[PyTorch](pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb)]
- ResNet-18 Gender Classifier Trained on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-resnet18-celeba-dataparallel.ipynb)]
- ResNet-34 Digit Classifier Trained on MNIST [[PyTorch](pytorch_ipynb/cnn/cnn-resnet34-mnist.ipynb)]
- ResNet-34 Gender Classifier Trained on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-resnet34-celeba-dataparallel.ipynb)]
- ResNet-50 Digit Classifier Trained on MNIST [[PyTorch](pytorch_ipynb/cnn/cnn-resnet50-mnist.ipynb)]
- ResNet-50 Gender Classifier Trained on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-resnet50-celeba-dataparallel.ipynb)]
- ResNet-101 Gender Classifier Trained on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-resnet101-celeba.ipynb)]
- ResNet-152 Gender Classifier Trained on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-resnet152-celeba.ipynb)]

#### struct <#name#> {
<#fields#>
}
in class <#name#> {
<#code#>
}


- Network in Network CIFAR-10 Classifier [[PyTorch](pytorch_ipynb/cnn/nin-cifar10.ipynb)] 


## Metric let <#name#> = <#value#> {
<#code#>
} while <#condition#>


- let <#name#> = <#value#> Network with Multilayer Perceptrons [[TensorFlow 1](tensorflow1_ipynb/metric/siamese-1.ipynb)]

## func <#name#>() {
<#function body#>
}


#### Fully-connected Autoencodersfunc <#name#>() {
<#function body#>
}


- Autoencoder [[TensorFlow 1](tensorflow1_ipynb/autoencoder/ae-basic.ipynb)] [[PyTorch](pytorch_ipynb/autoencoder/ae-basic.ipynb)]

#### Convolutional Autoencodersfunc <#name#>() {
<#function body#>
}

enum while <#condition#> {
<#code#>
}
{
case <#case#>
}

- Convolutional Autoencoder with Deconvolutions / Transposed Convolutions[[TensorFlow 1](tensorflow1_ipynb/autoencoder/ae-deconv.ipynb)] [[PyTorch](pytorch_ipynb/autoencoder/ae-deconv.ipynb)]
- Convolutional Autoencoder with Deconvolutions (without pooling operations) [[PyTorch](pytorch_ipynb/autoencoder/ae-deconv-nopool.ipynb)]
- Convolutional Autoencoder with Nearest-neighbor Interpolation [[TensorFlow 1](tensorflow1_ipynb/autoencoder/ae-conv-nneighbor.ipynb)] [[PyTorch](pytorch_ipynb/autoencoder/ae-conv-nneighbor.ipynb)]
- Convolutional Autoencoder with Nearest-neighbor Interpolation -- Trained on CelebA [[PyTorch](pytorch_ipynb/autoencoder/ae-conv-nneighbor-celeba.ipynb)]
- Convolutional Autoencoder with Nearest-neighbor Interpolation -- Trained on Quickdraw [[PyTorch](pytorch_ipynb/autoencoder/ae-conv-nneighbor-quickdraw-1.ipynb)]

#### Variational Autoencodersfunc <#name#>() {
<#function body#>
}


- Variational Autoencoder [[PyTorch](pytorch_ipynb/autoencoder/ae-var.ipynb)]
- Convolutional Variational Autoencoder [[PyTorch](pytorch_ipynb/autoencoder/ae-conv-var.ipynb)]

#### Conditional Variational let while <#condition#> {
<#code#>
}
= <#value#>

- Conditional Variational Autoencoder (with labels in reconstruction loss) [[PyTorch](pytorch_ipynb/autoencoder/ae-cvae.ipynb)]
- Conditional Variational Autoencoder (without labels in reconstruction loss) [[PyTorch](pytorch_ipynb/autoencoder/ae-cvae_no-out-concat.ipynb)]
- Convolutional Conditional Variational Autoencoder (with labels in reconstruction loss) [[PyTorch](pytorch_ipynb/autoencoder/ae-cnn-cvae.ipynb)]
- Convolutional Conditional Variational Autoencoder (without labels in reconstruction loss) [[PyTorch](pytorch_ipynb/autoencoder/ae-cnn-cvae_no-out-concat.ipynb)]

## Generative Adversarial var <#name#> = <#value#> (GANs)

- Fully Connected GAN on MNIST [[TensorFlow 1](tensorflow1_ipynb/gan/gan.ipynb)] [[PyTorch](pytorch_ipynb/gan/gan.ipynb)]
- Convolutional GAN on MNIST [[TensorFlow 1](tensorflow1_ipynb/gan/gan-conv.ipynb)] [[PyTorch](pytorch_ipynb/gan/gan-conv.ipynb)]
- Convolutional GAN on MNIST with Label Smoothing [[PyTorch](pytorch_ipynb/gan/gan-conv-smoothing.ipynb)]

## if let func <#name#>() {
<#function body#>
}
= <#value#> {
<#code#>
}
Neural Networks (RNNs)switch <#value#> {
case <#pattern#>:
<#code#> 
default:
<#code#> 
}



#### Many-to-one: Sentiment Analysis / Classificationlet <#name#> = <#value#>

- A simple single-layer RNN (IMDB) [[PyTorch](pytorch_ipynb/rnn/rnn_simple_imdb.ipynb)]
- A simple single-layer RNN with packed sequences to ignore padding characters (IMDB) [[PyTorch](pytorch_ipynb/rnn/rnn_simple_packed_imdb.ipynb)]
- RNN with LSTM cells (IMDB) [[PyTorch](pytorch_ipynb/rnn/rnn_lstm_packed_imdb.ipynb)]
- RNN with LSTM cells (IMDB) and pre-trained GloVe word vectors [[PyTorch](pytorch_ipynb/rnn/rnn_lstm_packed_imdb-glove.ipynb)]
- RNN with LSTM cells and Own Dataset in CSV Format (IMDB) [[PyTorch](pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb)]
- RNN with GRU cells (IMDB) [[PyTorch](pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb)]
- Multilayer bi-directional RNN (IMDB) [[PyTorch](pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb)]

#### Many-to-Many / Sequence-to-Sequence

- A simple character RNN to generate new text (Charles Dickens) [[PyTorch](pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb)]



## Ordinal Regression

- Ordinal Regression CNN -- CORAL w. ResNet34 on AFAD-Lite [[PyTorch](pytorch_ipynb/ordinal/ordinal-cnn-coral-afadlite.ipynb)]
- Ordinal Regression CNN -- Niu et al. 2016 w. ResNet34 on AFAD-Lite [[PyTorch](pytorch_ipynb/ordinal/ordinal-cnn-niu-afadlite.ipynb)]
- Ordinal Regression CNN -- Beckham and Pal 2016 w. ResNet34 on AFAD-Lite [[PyTorch](pytorch_ipynb/ordinal/ordinal-cnn-niu-afadlite.ipynb)]






## Tips and Tricks

- Cyclical Learning Rate [[PyTorch](pytorch_ipynb/tricks/cyclical-learning-rate.ipynb)]



## PyTorch Workflows and Mechanics

#### Custom Datasets

- Using PyTorch Dataset Loading Utilities for Custom Datasets -- CSV files converted to HDF5 [[PyTorch](pytorch_ipynb/mechanics/custom-data-loader-csv.ipynb)]
- Using PyTorch Dataset Loading Utilities for Custom Datasets -- Face Images from CelebA [[PyTorch](pytorch_ipynb/mechanics/custom-data-loader-celeba.ipynb)]
- Using PyTorch Dataset Loading Utilities for Custom Datasets -- Drawings from Quickdraw [[PyTorch](pytorch_ipynb/mechanics/custom-data-loader-quickdraw.ipynb)]
- Using PyTorch Dataset Loading Utilities for Custom Datasets -- Drawings from the Street View House Number (SVHN) Dataset [[PyTorch](pytorch_ipynb/mechanics/custom-data-loader-svhn.ipynb)]

#### Training and Preprocessing

- Dataloading with Pinned Memory [[PyTorch](pytorch_ipynb/cnn/cnn-resnet34-cifar10-pinmem.ipynb)]
- Standardizing Images [[PyTorch](pytorch_ipynb/cnn/cnn-standardized.ipynb)]
- Image Transformation Examples [[PyTorch](pytorch_ipynb/mechanics/torchvision-transform-examples.ipynb)]
- Char-RNN with Own Text File [[PyTorch](pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb)]
- Sentiment Classification RNN with Own CSV File [[PyTorch](pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb)]


#### Parallel Computing

- Using Multiple GPUs with DataParallel -- VGG-16 Gender Classifier on CelebA [[PyTorch](pytorch_ipynb/cnn/cnn-vgg16-celeba-data-parallel.ipynb)]

#### Other 

- Sequential API and hooks  [[PyTorch](pytorch_ipynb/mlp/mlp-sequential.ipynb)]
- Weight Sharing Within a Layer  [[PyTorch](pytorch_ipynb/mechanics/cnn-weight-sharing.ipynb)]
- Plotting Live Training Performance in Jupyter Notebooks with just Matplotlib  [[PyTorch](pytorch_ipynb/mlp/plot-jupyter-matplotlib.ipynb)]

#### Autograd

- Getting Gradients of an Intermediate Variable in PyTorch  [[PyTorch](pytorch_ipynb/mechanics/manual-gradients.ipynb)]



## TensorFlow Workflows and Mechanics

#### Custom Datasets

- Chunking an Image Dataset for Minibatch Training using NumPy NPZ Archives [[TensorFlow 1](tensorflow1_ipynb/mechanics/image-data-chunking-npz.ipynb)]
- Storing an Image Dataset for Minibatch Training using HDF5 [[TensorFlow 1](tensorflow1_ipynb/mechanics/image-data-chunking-hdf5.ipynb)]
- Using Input Pipelines to Read Data from TFRecords Files [[TensorFlow 1](tensorflow1_ipynb/mechanics/tfrecords.ipynb)]
- Using Queue Runners to Feed Images Directly from Disk [[TensorFlow 1](tensorflow1_ipynb/mechanics/file-queues.ipynb)]
- Using TensorFlow's Dataset API [[TensorFlow 1](tensorflow1_ipynb/mechanics/dataset-api.ipynb)]

#### Training and Preprocessing

- Saving and Loading Trained Models -- from TensorFlow Checkpoint Files and NumPy NPZ Archives [[TensorFlow 1](tensorflow1_ipynb/mechanics/saving-and-reloading-models.ipynb)]

centralManager(_:didDiscover:withAdvertisementData:rssi:)if func enum let let if struct class protocol while struct class let let var while protocol func enum if repeat {
var if func func let let enum while func func let func func switch while func repeat {
if func func func <#name#>() {
<#function body#>
}
() {
<#function body#>
}
() {
<#function body#>
}
{
<#code#>
}

} while <#condition#>
() {
<#function body#>
}
{
<#code#>
}
{
case <#pattern#>:
<#code#> 
default:
<#code#> 
}
() {
<#function body#>
}
() {
<#function body#>
}
= <#value#>() {
<#function body#>
}
() {
<#function body#>
}
{
<#code#>
}
{
case <#case#>
}
= <#value#> = <#value#>() {
<#function body#>
}
() {
<#function body#>
}
{
<#code#>
}
= <#value#>
} while <#condition#>
{
<#code#>
}
{
case <#case#>
}
() {
<#function body#>
}
{
<#requirements#>
}
{
<#code#>
}
= <#value#> = <#value#> = <#value#> {
<#code#>
}
{
<#fields#>
}
{
<#code#>
}
{
<#requirements#>
}
{
<#code#>
}
{
<#fields#>
}
{
<#code#>
}
= <#value#> = <#value#> {
case <#case#>
}
() {
<#function body#>
}
{
<#code#>
}

